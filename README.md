Demand Forecasting Using Machine Learning
 A Machine Learning-based Demand Forecasting system trained and deployed on AWS SageMaker
 
 
 ğŸ“Œ Overview
Demand forecasting is a crucial problem in supply chain management and retail. This project uses machine learning models like XGBoost, Random Forest, and Gradient Boosting to predict future product demand based on historical sales data.

ğŸ”¹ Key Steps Covered:
âœ” Data Preprocessing (handling missing values, outliers, feature engineering)
âœ” Model Training (XGBoost, Random Forest, Gradient Boosting, Prophet)
âœ” Model Evaluation (comparing MAE, MSE, RÂ²)
âœ” AWS SageMaker Deployment (automatic model deployment pipeline)
âœ” CI/CD Pipeline (for automated deployment updates)

ğŸ“‚ Project Structure


Demand_Forecasting_Project/
â”‚â”€â”€ data/                    # Raw & processed datasets  
â”‚â”€â”€ models/                  # Trained models & artifacts  
â”‚â”€â”€ notebooks/               # Jupyter Notebooks for each step  
â”‚â”€â”€ plots/                   # Visualizations & saved plots  
â”‚â”€â”€ src/                     # Python scripts for preprocessing & modeling  
â”‚â”€â”€ forecasting_env/         # Virtual environment for dependencies  
â”‚â”€â”€ model-config.json        # SageMaker model configuration  
â”‚â”€â”€ bucket-policy.json       # S3 bucket permissions  
â”‚â”€â”€ .env                     # AWS credentials (DO NOT COMMIT)  
â”‚â”€â”€ .gitignore               # Files to ignore in Git  
â”‚â”€â”€ README.md                # Project documentation  
â”‚â”€â”€ 01_data_loading.ipynb    # Load & verify raw dataset  
â”‚â”€â”€ 02_eda.ipynb             # Perform Exploratory Data Analysis (EDA)  
â”‚â”€â”€ 03_feature_engineering.ipynb  # Feature selection & transformation  
â”‚â”€â”€ 04_model_training.ipynb  # Train multiple models & select the best one  
â”‚â”€â”€ 05_deployment_testing.ipynb  # Deploy to AWS SageMaker & test inference


ğŸ“Š Model Performance Comparison
Model				MAE			MSE				RÂ²
XGBoost				0.373834	0.251892	0.7462
Random Forest		0.375562	0.272121	0.7258
Gradient Boosting	0.573512	0.555499	0.4403
âœ… XGBoost performed the best and was selected for deployment.

ğŸ›  Technologies Used
Python (pandas, numpy, scikit-learn, XGBoost)
Jupyter Notebook (for EDA & training)
AWS SageMaker (for model deployment)
Amazon S3 (for storing datasets & models)
GitHub Actions (for CI/CD automation)
ğŸš€ Deployment Process
1ï¸âƒ£ Train the Model (04_model_training.ipynb)
After feature engineering, models are trained and the best-performing model is saved as .pkl.

2ï¸âƒ£ Convert & Package Model (05_deployment_testing.ipynb)
Convert .pkl â†’ .model (XGBoost native format)
Package as .tar.gz (required for SageMaker)
Upload to Amazon S3
3ï¸âƒ£ Deploy Model to AWS SageMaker
Automatically delete previous endpoint if exists
Deploy new model & wait until InService
Test inference on deployed model
âœ… The entire process is automated in 05_deployment_testing.ipynb.

ğŸ“Œ How to Run This Project
1ï¸âƒ£ Clone the Repository
git clone https://github.com/himanu-dandle/demand-forecasting.git
cd demand-forecasting

2ï¸âƒ£ Set Up Virtual Environment & Install Dependencies
python -m venv forecasting_env
source forecasting_env/bin/activate  # For Mac/Linux
forecasting_env\Scripts\activate     # For Windows
pip install -r requirements.txt

3ï¸âƒ£ Configure AWS Credentials
Create a .env file in the project root (DO NOT COMMIT THIS FILE).
SAGEMAKER_BUCKET=demand-forecasting-bucket-us-east-1
SAGEMAKER_ROLE=arn:aws:iam::060795905003:role/service-role/AmazonSageMaker-ExecutionRole-XXXXX

4ï¸âƒ£ Train the Model
jupyter notebook 04_model_training.ipynb

5ï¸âƒ£ Deploy the Model to AWS SageMaker
jupyter notebook 05_deployment_testing.ipynb

ğŸ“Œ Inference: Making Predictions with Deployed Model
Once the model is deployed, you can send real-time inference requests:

python


import boto3
import json

runtime = boto3.client("sagemaker-runtime")

ENDPOINT_NAME = "xgboost-demand-forecasting-endpoint"

test_input = json.dumps({"instances": [[5.2, 3.1, 1.4, 0.2]]})  # Modify as needed

response = runtime.invoke_endpoint(
    EndpointName=ENDPOINT_NAME,
    ContentType="application/json",
    Body=test_input
)

result = json.loads(response["Body"].read().decode())
print("âœ… Prediction:", result)

ğŸš€ CI/CD Pipeline (Auto-Deploy with GitHub Actions)
Every time new code is pued to GitHub, the CI/CD pipeline:
âœ… Runs tests
âœ… Re-trains the model (if needed)
âœ… Deploys the new model to AWS SageMaker
âš¡ Want to enable GitHub Actions for automatic deployment? Let me know!

ğŸ“Œ Future Improvements
ğŸ”¹ Add Deep Learning models (LSTMs, Transformers for time series forecasting)
ğŸ”¹ Enable Hyperparameter tuning for better performance
ğŸ”¹ Set up API Gateway for model inference requests

ğŸ“© Contact & Contributions
ğŸ™‹â€â™‚ï¸ Author: Himanshu Dandle
ğŸ“§ Email: himanshu.dandle@gmail.com
ğŸ”— GitHub: himanshu-dandle



